{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubnps23/tecHub/AD_intro/advattacks_iitp_summer/a3_env/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import optuna\n",
    "import os, sys\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mconfig_examples\u001b[0m/  \u001b[01;34mdatasets\u001b[0m/  \u001b[01;34mnotebooks\u001b[0m/  README.md  \u001b[01;34msource\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "# changing core directory\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "os.chdir('..')\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.training.early_stopping import EarlyStopping\n",
    "from source.data.power_cons import load_powercons, PowerConsDataset\n",
    "\n",
    "# from source.training.activation import Activation\n",
    "\n",
    "from source.classifiers.LSTM_Classifier import LSTMClassifier\n",
    "from source.classifiers.ResCNN_Classifier import ResCNNClassifier\n",
    "from source.classifiers.PatchTST_classifier import PatchTSTClassifier\n",
    "from source.training.train_classifier import train_classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1000\n",
    "random.seed(SEED)\n",
    "os.environ[\"PYTHONHASHSEED\"] = str(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_PATH = Path('datasets/PowerCons_TRAIN.tsv')\n",
    "TEST_PATH = Path('datasets/PowerCons_TEST.tsv')\n",
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (180, 144, 1) Test shape: (180, 144, 1) n_classes: 2\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, classes_ = load_powercons(TRAIN_PATH)\n",
    "X_test, y_test, _ = load_powercons(TEST_PATH)\n",
    "n_classes = len(classes_)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape, 'n_classes:', n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.6031435 6.4025993 -1.6804967 5.9844995\n"
     ]
    }
   ],
   "source": [
    "print(X_train.min(), X_train.max(), X_test.min(), X_test.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = PowerConsDataset(X_train, y_train)\n",
    "test_ds = PowerConsDataset(X_test, y_test)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "counts:\n",
      "1    90\n",
      "2    90\n",
      "Name: 0, dtype: int64\n",
      "shares:\n",
      "1    0.5\n",
      "2    0.5\n",
      "Name: 0, dtype: float64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check data-balance\n",
    "df = pd.read_csv(TRAIN_PATH, sep='\\t', header=None)\n",
    "\n",
    "label_counts = df.iloc[:, 0].value_counts().sort_index()\n",
    "print(f'counts:\\n{label_counts}')     \n",
    "print(f'shares:\\n{label_counts / len(df)}')\n",
    "\n",
    "\n",
    "label_counts.plot.bar()\n",
    "plt.title('Class distribution in TRAIN set')\n",
    "plt.xlabel('Class')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_worker(worker_id):\n",
    "    worker_seed = SEED + worker_id\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(SEED)\n",
    "train_dl = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, worker_init_fn=seed_worker, generator=g)\n",
    "test_dl = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=4, worker_init_fn=seed_worker, generator=g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train_loss=0.6967 acc=0.4611 | val_loss=0.6944 acc=0.5000\n",
      "Epoch 02: train_loss=0.6932 acc=0.5000 | val_loss=0.6917 acc=0.5000\n",
      "Epoch 03: train_loss=0.6898 acc=0.5000 | val_loss=0.6891 acc=0.5944\n",
      "Epoch 04: train_loss=0.6868 acc=0.5833 | val_loss=0.6865 acc=0.5833\n",
      "Epoch 05: train_loss=0.6844 acc=0.5778 | val_loss=0.6841 acc=0.5500\n",
      "Epoch 06: train_loss=0.6804 acc=0.5944 | val_loss=0.6819 acc=0.5556\n",
      "Epoch 07: train_loss=0.6775 acc=0.5944 | val_loss=0.6796 acc=0.5611\n",
      "Epoch 08: train_loss=0.6744 acc=0.6000 | val_loss=0.6768 acc=0.5611\n",
      "Epoch 09: train_loss=0.6696 acc=0.6000 | val_loss=0.6738 acc=0.5667\n",
      "Epoch 10: train_loss=0.6644 acc=0.6111 | val_loss=0.6698 acc=0.5778\n",
      "Epoch 11: train_loss=0.6578 acc=0.6222 | val_loss=0.6640 acc=0.5889\n",
      "Epoch 12: train_loss=0.6470 acc=0.6444 | val_loss=0.6533 acc=0.6111\n",
      "Epoch 13: train_loss=0.6277 acc=0.6667 | val_loss=0.6296 acc=0.6556\n",
      "Epoch 14: train_loss=0.5877 acc=0.6944 | val_loss=0.5663 acc=0.7111\n",
      "Epoch 15: train_loss=0.4995 acc=0.7500 | val_loss=0.4290 acc=0.8222\n",
      "Epoch 16: train_loss=0.4287 acc=0.8333 | val_loss=0.3687 acc=0.8778\n",
      "Epoch 17: train_loss=0.3837 acc=0.8500 | val_loss=0.3979 acc=0.8556\n",
      "Epoch 18: train_loss=0.3584 acc=0.8889 | val_loss=0.4118 acc=0.8500\n",
      "Epoch 19: train_loss=0.3558 acc=0.8944 | val_loss=0.3729 acc=0.8833\n",
      "Epoch 20: train_loss=0.3425 acc=0.8722 | val_loss=0.3307 acc=0.8889\n",
      "Epoch 21: train_loss=0.3426 acc=0.8667 | val_loss=0.3498 acc=0.8556\n",
      "Epoch 22: train_loss=0.3261 acc=0.8722 | val_loss=0.3787 acc=0.8500\n",
      "Epoch 23: train_loss=0.3112 acc=0.8833 | val_loss=0.3340 acc=0.8722\n",
      "Epoch 24: train_loss=0.3086 acc=0.8889 | val_loss=0.3246 acc=0.8833\n",
      "Epoch 25: train_loss=0.2965 acc=0.8833 | val_loss=0.3401 acc=0.8833\n",
      "Epoch 26: train_loss=0.2944 acc=0.8889 | val_loss=0.3426 acc=0.8556\n",
      "Epoch 27: train_loss=0.2847 acc=0.8889 | val_loss=0.3282 acc=0.8611\n",
      "Epoch 28: train_loss=0.2810 acc=0.8889 | val_loss=0.3127 acc=0.8833\n",
      "Epoch 29: train_loss=0.2821 acc=0.8944 | val_loss=0.3322 acc=0.8611\n",
      "Epoch 30: train_loss=0.2845 acc=0.9000 | val_loss=0.3372 acc=0.8778\n",
      "Epoch 31: train_loss=0.2827 acc=0.8944 | val_loss=0.3121 acc=0.8889\n",
      "Epoch 32: train_loss=0.2654 acc=0.8944 | val_loss=0.2925 acc=0.8944\n",
      "Epoch 33: train_loss=0.2746 acc=0.8889 | val_loss=0.3005 acc=0.8667\n",
      "Epoch 34: train_loss=0.2699 acc=0.8778 | val_loss=0.3176 acc=0.8722\n",
      "Epoch 35: train_loss=0.2675 acc=0.9000 | val_loss=0.2947 acc=0.8889\n",
      "Epoch 36: train_loss=0.2562 acc=0.8889 | val_loss=0.2724 acc=0.9056\n",
      "Epoch 37: train_loss=0.2567 acc=0.9000 | val_loss=0.2710 acc=0.8667\n",
      "Epoch 38: train_loss=0.2557 acc=0.9111 | val_loss=0.2714 acc=0.8833\n",
      "Epoch 39: train_loss=0.2382 acc=0.9000 | val_loss=0.2674 acc=0.8778\n",
      "Epoch 40: train_loss=0.2519 acc=0.9056 | val_loss=0.2556 acc=0.8833\n",
      "Epoch 41: train_loss=0.2321 acc=0.9111 | val_loss=0.2634 acc=0.8889\n",
      "Epoch 42: train_loss=0.2347 acc=0.9111 | val_loss=0.2431 acc=0.9167\n",
      "Epoch 43: train_loss=0.2246 acc=0.9111 | val_loss=0.2430 acc=0.9111\n",
      "Epoch 44: train_loss=0.2219 acc=0.9111 | val_loss=0.2369 acc=0.9111\n",
      "Epoch 45: train_loss=0.2163 acc=0.9111 | val_loss=0.2350 acc=0.9000\n",
      "Epoch 46: train_loss=0.2127 acc=0.9167 | val_loss=0.2270 acc=0.9222\n",
      "Epoch 47: train_loss=0.2168 acc=0.9111 | val_loss=0.2373 acc=0.9111\n",
      "Epoch 48: train_loss=0.2118 acc=0.9111 | val_loss=0.2162 acc=0.9222\n",
      "Epoch 49: train_loss=0.2042 acc=0.9222 | val_loss=0.2139 acc=0.9222\n",
      "Epoch 50: train_loss=0.1976 acc=0.9167 | val_loss=0.2119 acc=0.9222\n"
     ]
    }
   ],
   "source": [
    "clf_LSTM = LSTMClassifier(n_classes, hidden_size=50, num_layers=1)\n",
    "\n",
    "history, _, _=  train_classifier(\n",
    "    clf_LSTM,\n",
    "    train_dl,\n",
    "    val_loader=test_dl,\n",
    "    epochs=2,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    patience=4,\n",
    "    verbose_every=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 01: train_loss=0.5020 acc=0.7167 | val_loss=0.4530 acc=0.8556\n",
      "Epoch 02: train_loss=0.3624 acc=0.8389 | val_loss=0.4647 acc=0.7722\n"
     ]
    }
   ],
   "source": [
    "clf_resCNN = ResCNNClassifier(n_classes=n_classes, x_dim=1).to(device)\n",
    "\n",
    "history, best_val, best_state = train_classifier(\n",
    "    clf_resCNN,\n",
    "    train_loader=train_dl,\n",
    "    val_loader=test_dl,\n",
    "    epochs=2,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    patience=10,\n",
    "    verbose_every=1\n",
    ")\n",
    "\n",
    "torch.save(best_state, \"rescnn_classifier_best.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence length = 144\n"
     ]
    }
   ],
   "source": [
    "loader = train_dl\n",
    "x, _ = next(iter(loader))\n",
    "seq_len = x.size(1)\n",
    "print(\"Sequence length =\", seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 02: train_loss=2.6224 acc=0.7778 | val_loss=1.9763 acc=0.8611\n",
      "Epoch 04: train_loss=0.8798 acc=0.9389 | val_loss=1.0531 acc=0.8944\n"
     ]
    }
   ],
   "source": [
    "patch_params = dict(\n",
    "    seq_len=seq_len,\n",
    "    n_layers=3,\n",
    "    n_heads=8,\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    dropout=0.4,\n",
    "    attn_dropout=0.0,\n",
    "    patch_len=40,\n",
    "    stride=24,\n",
    "    padding_patch=True,\n",
    "    revin=True,\n",
    "    affine=False,\n",
    "    individual=False,\n",
    "    subtract_last=False,\n",
    "    decomposition=False,\n",
    "    kernel_size=25,\n",
    "    activation=\"gelu\",\n",
    "    norm=\"BatchNorm\",\n",
    "    pre_norm=False,\n",
    "    res_attention=True,\n",
    "    store_attn=False,\n",
    ")\n",
    "\n",
    "clf_PatchTST = PatchTSTClassifier(\n",
    "    n_classes=n_classes,\n",
    "    x_dim=1,\n",
    "    activation_type=\"identity\",\n",
    "    patch_kwargs=patch_params\n",
    ").to(device)\n",
    "\n",
    "history, best_val, best_wts = train_classifier(\n",
    "    model=clf_PatchTST,\n",
    "    train_loader=train_dl,\n",
    "    val_loader=test_dl,\n",
    "    epochs=2,\n",
    "    lr=1e-3,\n",
    "    weight_decay=1e-4,\n",
    "    device=device,\n",
    "    patience=8,\n",
    "    verbose_every=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_TARGET = clf_PatchTST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.attacks.iFGSM import FGSMAttack, iFGSMAttack\n",
    "from source.attacks.PGD import PGDAttack \n",
    "\n",
    "from source.attacks.attackLSTM import AttackLSTM\n",
    "from source.attacks.attackResCNN import AttackCNN\n",
    "from source.attacks.attackPatchTST import AttackPatchTST \n",
    "\n",
    "from source.attacks.mba import ModelBasedAttack \n",
    "\n",
    "from source.training.train_attacker import train_atk_model\n",
    "from source.training.train_iter_attack import train_attack_iter, prepare_victim_for_input_grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01 | victim‑loss 0.5128 | acc 0.9611\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.512811976008945, 0.9611111124356587)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atk_LSTM = AttackLSTM(hidden_dim=128, dropout=0.6, x_dim=1, activation_type='tanh').to(device)\n",
    "for p in clf_LSTM.parameters():\n",
    "    p.requires_grad_(False)\n",
    "# clf_LSTM.eval()\n",
    "\n",
    "eps_LSTM = 1.371353\n",
    "train_atk_model(atk_LSTM,\n",
    "                LEARNING_TARGET,\n",
    "                train_dl,\n",
    "                eps=eps_LSTM,\n",
    "                epochs=1,\n",
    "                lr=1e-1,\n",
    "                alpha_l2=6e-4,\n",
    "                device=device,\n",
    "                patience=9\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    eps = trial.suggest_float(\"eps\",    0.5, 2.0,    log=True)\n",
    "    lr  = trial.suggest_float(\"lr\",     1e-3, 1e-2,   log=True)\n",
    "    alpha_l2  = trial.suggest_float(\"alpha_l2\", 1e-5, 1e-1, log=True)\n",
    "    patience  = trial.suggest_int(\"patience\", 3, 10)\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "    dropout = trial.suggest_float(\"dropout\", 0.1, 0.6, step=0.1)\n",
    "\n",
    "    atk_model = AttackLSTM(\n",
    "        hidden_dim=hidden_dim, x_dim=1,\n",
    "        activation_type='tanh', dropout=dropout\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = train_atk_model(\n",
    "        atk_model, clf_LSTM, train_dl,\n",
    "        eps=eps,  epochs=50, lr=lr, alpha_l2=alpha_l2,\n",
    "        device=device, patience=patience\n",
    "    )\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(),\n",
    "#                             pruner=optuna.pruners.MedianPruner(n_warmup_steps=3))\n",
    "\n",
    "# study.optimize(objective, n_trials=50, timeout=60*60)\n",
    "# print(\"BEST PARAMS:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ResCNN attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01 | victim‑loss 2.4237 | acc 0.6611\n",
      "\n",
      "Epoch 02 | victim‑loss 5.7410 | acc 0.2556\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(5.741018507215712, 0.25555555555555554)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atk_resCNN = AttackCNN().to(device)\n",
    "atk_resCNN = AttackCNN(hidden_dim=64, x_dim=1, activation_type='tanh').to(device)\n",
    "\n",
    "# weights_path = 'weights/surr_resCNNfc_CPU_0.28.pth'\n",
    "\n",
    "eps_resCNN = 2\n",
    "train_atk_model(atk_resCNN, LEARNING_TARGET, train_dl,\n",
    "                eps=eps_resCNN,\n",
    "                epochs=2, lr=2e-4, alpha_l2=4.5e-05,\n",
    "                device=device, patience=10, is_debugged=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    eps = trial.suggest_float(\"eps\",    0.5, 2.0,    log=True)\n",
    "    lr  = trial.suggest_float(\"lr\",     1e-3, 1e-2,   log=True)\n",
    "    alpha_l2  = trial.suggest_float(\"alpha_l2\", 1e-5, 1e-1, log=True)\n",
    "    patience  = trial.suggest_int(\"patience\", 3, 10)\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "\n",
    "    atk_model = AttackCNN(hidden_dim=hidden_dim, x_dim=1, activation_type='tanh')\n",
    "\n",
    "    val_loss, val_acc = train_atk_model(\n",
    "        atk_model, clf_LSTM, train_dl,\n",
    "        eps=eps,  epochs=50, lr=lr, alpha_l2=alpha_l2,\n",
    "        device=device, patience=patience\n",
    "    )\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\", sampler=optuna.samplers.TPESampler(),\n",
    "#                             pruner=optuna.pruners.MedianPruner(n_warmup_steps=3))\n",
    "# study.optimize(objective, n_trials=50, timeout=60*60)\n",
    "# print(\"BEST PARAMS:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PatchTST Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 01 | victim‑loss 0.5375 | acc 0.9611\n",
      "\n",
      "Epoch 02 | victim‑loss 0.4949 | acc 0.9500\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.4949381139543321, 0.949999992052714)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_params = dict(\n",
    "    seq_len=seq_len,\n",
    "    n_layers=3,\n",
    "    n_heads=8,\n",
    "    d_model=512,\n",
    "    d_ff=2048,\n",
    "    dropout=0.4,\n",
    "    attn_dropout=0.0,\n",
    "    patch_len=28,\n",
    "    stride=24,\n",
    "    padding_patch=True,\n",
    "    revin=True,\n",
    "    affine=False,\n",
    "    individual=False,\n",
    "    subtract_last=False,\n",
    "    decomposition=False,\n",
    "    kernel_size=25,\n",
    "    activation=\"gelu\",\n",
    "    norm=\"BatchNorm\",\n",
    "    pre_norm=False,\n",
    "    res_attention=True,\n",
    "    store_attn=False,\n",
    ")\n",
    "\n",
    "atk_PatchTST = AttackPatchTST(\n",
    "    hidden_dim=256,\n",
    "    x_dim=1,\n",
    "    activation_type=\"tanh\",\n",
    "    patch_kwargs=patch_params,\n",
    ")\n",
    "\n",
    "eps_PatchTST = 1\n",
    "train_atk_model(atk_PatchTST, clf_PatchTST, train_dl,\n",
    "                eps=eps_PatchTST,\n",
    "                epochs=2, lr=2e-4, alpha_l2=1e-4,\n",
    "                device=device, patience=8, is_debugged=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEQ_LEN  = seq_len\n",
    "X_DIM    = 1\n",
    "DEVICE   = device\n",
    "VICTIM   = LEARNING_TARGET\n",
    "TRAIN_DL = train_dl\n",
    "\n",
    "def objective(trial: optuna.Trial):\n",
    "\n",
    "    # atk params\n",
    "    eps        = trial.suggest_float(\"eps\",        0.1, 2,    log=True)\n",
    "    lr         = trial.suggest_float(\"lr\",         1e-4, 1e0,  log=True)\n",
    "    alpha_l2   = trial.suggest_float(\"alpha_l2\",   1e-5, 1e-2,  log=True)\n",
    "    patience   = trial.suggest_int  (\"patience\",   3, 10)\n",
    "\n",
    "    # architecture\n",
    "    hidden_dim = trial.suggest_categorical(\"hidden_dim\", [64, 128, 256])\n",
    "\n",
    "    # main hyperparams\n",
    "    patch_len  = trial.suggest_int(\"patch_len\", 8, 48, step=4)\n",
    "    stride_max = patch_len                      # stride не может превышать patch_len\n",
    "    stride     = trial.suggest_int(\"stride\",    4, stride_max, step=4)\n",
    "    n_layers   = trial.suggest_int(\"n_layers\",  1, 4)\n",
    "    d_model    = trial.suggest_categorical(\"d_model\", [256, 512, 768])\n",
    "    dropout    = trial.suggest_float(\"dropout\", 0.1, 0.6, step=0.1)\n",
    "\n",
    "    # patch-kwargs\n",
    "    patch_kwargs = dict(\n",
    "        seq_len       = SEQ_LEN,\n",
    "        n_layers      = n_layers,\n",
    "        n_heads       = 8,\n",
    "        d_model       = d_model,\n",
    "        d_ff          = 4 * d_model,\n",
    "        dropout       = dropout,\n",
    "        attn_dropout  = 0.0,\n",
    "        patch_len     = patch_len,\n",
    "        stride        = stride,\n",
    "        padding_patch = True,\n",
    "        revin         = True,\n",
    "        affine        = False,\n",
    "        individual    = False,\n",
    "        subtract_last = False,\n",
    "        decomposition = False,\n",
    "        kernel_size   = 25,\n",
    "        activation    = \"gelu\",\n",
    "        norm          = \"BatchNorm\",\n",
    "        pre_norm      = False,\n",
    "        res_attention = True,\n",
    "        store_attn    = False,\n",
    "    )\n",
    "\n",
    "    surrogate = AttackPatchTST(\n",
    "        hidden_dim     = hidden_dim,\n",
    "        x_dim          = X_DIM,\n",
    "        activation_type= \"tanh\",\n",
    "        patch_kwargs   = patch_kwargs\n",
    "    )\n",
    "\n",
    "    val_loss, val_acc = train_atk_model(\n",
    "        surrogate, VICTIM, TRAIN_DL,\n",
    "        eps=eps, epochs=50, lr=lr, alpha_l2=alpha_l2,\n",
    "        device=DEVICE, patience=patience\n",
    "    )\n",
    "\n",
    "    return val_acc\n",
    "\n",
    "\n",
    "# sampler = optuna.samplers.TPESampler()\n",
    "# pruner  = optuna.pruners.MedianPruner(n_warmup_steps=3)\n",
    "\n",
    "# study = optuna.create_study(direction=\"minimize\", sampler=sampler, pruner=pruner)\n",
    "# study.optimize(objective, n_trials=50, timeout=60*60)\n",
    "\n",
    "# print(\"BEST PARAMS:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iter-PatchTST attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Δ] mean ||δ||_2 = 1.024 | mean ||δ||_∞ = 0.089\n",
      "[Δ] mean ||x||_2 = 10.936 | mean ||x_adv||_2 = 11.393\n",
      "[Δ] mean ||δ||_2 = 1.152 | mean ||δ||_∞ = 0.100\n",
      "[Δ] mean ||x||_2 = 11.684 | mean ||x_adv||_2 = 12.089\n",
      "[Δ] mean ||δ||_2 = 1.516 | mean ||δ||_∞ = 0.130\n",
      "[Δ] mean ||x||_2 = 11.000 | mean ||x_adv||_2 = 11.580\n",
      "Epoch 01 | victim-loss 0.4845 | acc 0.9500\n",
      "[Δ] mean ||δ||_2 = 1.938 | mean ||δ||_∞ = 0.166\n",
      "[Δ] mean ||x||_2 = 10.740 | mean ||x_adv||_2 = 11.297\n",
      "[Δ] mean ||δ||_2 = 2.067 | mean ||δ||_∞ = 0.176\n",
      "[Δ] mean ||x||_2 = 11.039 | mean ||x_adv||_2 = 11.651\n",
      "[Δ] mean ||δ||_2 = 2.532 | mean ||δ||_∞ = 0.215\n",
      "[Δ] mean ||x||_2 = 12.035 | mean ||x_adv||_2 = 12.770\n",
      "Epoch 02 | victim-loss 0.4847 | acc 0.9500\n",
      "[done] val_loss=0.4847  |  val_acc(after attack)=0.9500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "attacker = AttackPatchTST(hidden_dim=256, x_dim=1, activation_type='tanh',\n",
    "                          patch_kwargs=patch_params).to(device)\n",
    "\n",
    "target = LEARNING_TARGET\n",
    "prepare_victim_for_input_grad(target)\n",
    "\n",
    "disc = None\n",
    "best = {'eps': 0.4,\n",
    "         'lr': 1e-4,\n",
    "         'alpha_l2': 1e-4,\n",
    "         'steps': 1, 'use_alpha_explicit': False, \n",
    "         'proj': 'none', 'proj_equal_eps': True, 'rand_init': False, 'bpda': False, \n",
    "         'use_sign': False, 'momentum_mu': 0.9, 'step_normalize': None, \n",
    "         'step_noise_std': 0.004, 'victim_eval': True, 'hidden_dim': 128}\n",
    "best['alpha'] = None\n",
    "\n",
    "alpha_explicit = None\n",
    "\n",
    "val_loss, val_acc = train_attack_iter(\n",
    "    attacker=attacker,\n",
    "    victim=target,\n",
    "    loader=train_dl,\n",
    "\n",
    "    eps=best[\"eps\"],\n",
    "    steps=best[\"steps\"],\n",
    "    alpha=alpha_explicit,\n",
    "    epochs=2,\n",
    "    lr=best[\"lr\"],\n",
    "    alpha_l2=best[\"alpha_l2\"],\n",
    "\n",
    "    lambda_disc=0.0,\n",
    "    disc=disc,\n",
    "    device=device,\n",
    "    patience=8,\n",
    "\n",
    "    data_clamp=None,\n",
    "    rand_init=best[\"rand_init\"],\n",
    "    use_sign=best[\"use_sign\"],\n",
    "    equal_eps=best[\"proj_equal_eps\"],\n",
    "    bpda=best[\"bpda\"],\n",
    "    verbose=True,\n",
    "\n",
    "    proj=best[\"proj\"],\n",
    "    proj_equal_eps=best[\"proj_equal_eps\"],\n",
    "    momentum_mu=best[\"momentum_mu\"],      \n",
    "    step_normalize=best[\"step_normalize\"],\n",
    "    step_noise_std=best[\"step_noise_std\"],\n",
    "    victim_eval=best[\"victim_eval\"],      \n",
    "    grad_clip=None,                       \n",
    ")\n",
    "\n",
    "print(f\"[done] val_loss={val_loss:.4f}  |  val_acc(after attack)={val_acc:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Сomparison of attacks"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a3_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
