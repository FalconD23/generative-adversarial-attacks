{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing core directory\n",
    "import os, sys\n",
    "dir2 = os.path.abspath('')\n",
    "dir1 = os.path.dirname(dir2)\n",
    "if not dir1 in sys.path:\n",
    "    sys.path.append(dir1)\n",
    "os.chdir('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sin_signal(n_time_points, n_points_in_ones):\n",
    "    t = np.linspace(0, n_time_points/n_points_in_ones , n_time_points)\n",
    "    w1 = np.random.normal(1, 0.01, size=(n_time_points))\n",
    "    fi = np.random.uniform(-0.1, 0.1, size=n_time_points)\n",
    "    signal = np.sin(t * w1 + fi)\n",
    "    return signal\n",
    "\n",
    "def generate_disc_signal(signal, win_disc):\n",
    "    n_time_points = len(signal)\n",
    "    new_signal = np.zeros(n_time_points)\n",
    "    for i in range(0, n_time_points-1, win_disc):\n",
    "        new_signal_part = signal[i:(i+win_disc)].mean()\n",
    "        new_signal[i:(i+win_disc)] = new_signal_part\n",
    "\n",
    "    return new_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 2000\n",
    "min_n_time_points = 50\n",
    "max_n_time_points = 100\n",
    "n_points_in_ones = 3\n",
    "win_disc = 7\n",
    "\n",
    "X_synth = np.zeros((n_samples, max_n_time_points))\n",
    "y_synth = np.repeat([0, 1], 1000).reshape(2, -1).T.reshape(-1, 1)\n",
    "\n",
    "for i_samp in range(0, n_samples, 2):\n",
    "\n",
    "    n_time_points = int(np.random.uniform(min_n_time_points, max_n_time_points))\n",
    "    \n",
    "    sin_signal = generate_sin_signal(n_time_points, n_points_in_ones)\n",
    "    disc_signal = generate_disc_signal(sin_signal, win_disc)\n",
    "\n",
    "    X_synth[i_samp, :n_time_points] = sin_signal\n",
    "    X_synth[i_samp + 1, :n_time_points] = disc_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.023927</td>\n",
       "      <td>0.332728</td>\n",
       "      <td>0.626686</td>\n",
       "      <td>0.828640</td>\n",
       "      <td>0.980440</td>\n",
       "      <td>0.988800</td>\n",
       "      <td>0.931743</td>\n",
       "      <td>0.765654</td>\n",
       "      <td>0.541405</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.030262</td>\n",
       "      <td>0.262890</td>\n",
       "      <td>0.628357</td>\n",
       "      <td>0.872193</td>\n",
       "      <td>0.962486</td>\n",
       "      <td>0.990720</td>\n",
       "      <td>0.903754</td>\n",
       "      <td>0.626032</td>\n",
       "      <td>0.499180</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>0.667132</td>\n",
       "      <td>-0.185633</td>\n",
       "      <td>-0.185633</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.035087</td>\n",
       "      <td>0.375331</td>\n",
       "      <td>0.638837</td>\n",
       "      <td>0.837876</td>\n",
       "      <td>0.991880</td>\n",
       "      <td>0.981919</td>\n",
       "      <td>0.889204</td>\n",
       "      <td>0.654002</td>\n",
       "      <td>0.515431</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.097725</td>\n",
       "      <td>0.253609</td>\n",
       "      <td>0.618900</td>\n",
       "      <td>0.788993</td>\n",
       "      <td>0.961905</td>\n",
       "      <td>0.980734</td>\n",
       "      <td>0.858261</td>\n",
       "      <td>0.729795</td>\n",
       "      <td>0.353422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0         1         2         3         4         5         6         7    \\\n",
       "0    0 -0.023927  0.332728  0.626686  0.828640  0.980440  0.988800  0.931743   \n",
       "1    0 -0.030262  0.262890  0.628357  0.872193  0.962486  0.990720  0.903754   \n",
       "2    1  0.667132  0.667132  0.667132  0.667132  0.667132  0.667132  0.667132   \n",
       "3    0 -0.035087  0.375331  0.638837  0.837876  0.991880  0.981919  0.889204   \n",
       "4    0  0.097725  0.253609  0.618900  0.788993  0.961905  0.980734  0.858261   \n",
       "\n",
       "        8         9    ...  91   92   93   94   95   96   97   98   99   100  \n",
       "0  0.765654  0.541405  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1  0.626032  0.499180  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2 -0.185633 -0.185633  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3  0.654002  0.515431  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4  0.729795  0.353422  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[5 rows x 101 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synth_dataset = np.concatenate([y_synth, X_synth], axis=1)\n",
    "\n",
    "synth_dataset = pd.DataFrame(synth_dataset)\n",
    "synth_dataset = synth_dataset.sample(frac=1).reset_index(drop=True)\n",
    "synth_dataset[0] = synth_dataset[0].astype(int)\n",
    "synth_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 0.8\n",
    "n_train = int(len(synth_dataset) * train_size)\n",
    "\n",
    "train_synth = synth_dataset.iloc[:n_train]\n",
    "test_synth = synth_dataset.iloc[n_train:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dir_path = 'data/TS2Vec/UCR/MySynth'\n",
    "# if not os.path.exists(dir_path): \n",
    "#     os.makedirs(dir_path) \n",
    "\n",
    "# train_synth.to_csv(os.path.join(dir_path, 'MySynth_TRAIN.tsv'), index=None, header=None, sep='\\t')\n",
    "# test_synth.to_csv(os.path.join(dir_path, 'MySynth_TEST.tsv'), index=None, header=None, sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/adversarial_attacks/miniconda/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "CUDA extension for structured kernels (Cauchy and Vandermonde multiplication) not found. Install by going to extensions/kernels/ and running `python setup.py install`, for improved speed and memory efficiency. Note that the kernel changed for state-spaces 4.0 and must be recompiled.\n",
      "Falling back on slow Cauchy and Vandermonde kernel. Install at least one of pykeops or the CUDA extension for better speed and memory efficiency.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import hydra\n",
    "import pandas as pd\n",
    "import torch\n",
    "from omegaconf import DictConfig\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.config import get_attack, get_criterion, get_disc_list, get_model\n",
    "from src.data import MyDataset, load_data, transform_data\n",
    "from src.estimation.estimators import AttackEstimator\n",
    "from src.utils import save_experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from omegaconf import OmegaConf\n",
    "\n",
    "initialize(config_path='../config/my_configs', version_base=None)\n",
    "\n",
    "cfg = compose(config_name='attack_run_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(cfg[\"cuda\"] if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = load_data(cfg['dataset'])\n",
    "X_train, X_test, y_train, y_test = transform_data(X_train, X_test, y_train, y_test, slice_data=cfg['slice'])\n",
    "\n",
    "test_loader = DataLoader(\n",
    "    MyDataset(X_test, y_test), \n",
    "    batch_size=cfg['batch_size'] , \n",
    "    shuffle=False\n",
    "    )\n",
    "\n",
    "\n",
    "device = torch.device(cfg[\"cuda\"] if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "attack_model_path = os.path.join(\n",
    "    cfg[\"model_folder\"],\n",
    "    cfg[\"attack_model\"][\"name\"],\n",
    "    f\"model_{cfg['model_id_attack']}_{cfg['dataset']}.pt\",\n",
    ")\n",
    "\n",
    "attack_model = get_model(\n",
    "    cfg[\"attack_model\"][\"name\"],\n",
    "    cfg[\"attack_model\"][\"params\"],\n",
    "    path=attack_model_path,\n",
    "    device=device,\n",
    "    train_mode=cfg[\"attack_model\"][\"attack_train_mode\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = get_criterion(cfg[\"criterion_name\"], cfg[\"criterion_params\"])\n",
    "\n",
    "disc_check_list = (\n",
    "    get_disc_list(\n",
    "        model_name=cfg[\"disc_model_check\"][\"name\"],\n",
    "        model_params=cfg[\"disc_model_check\"][\"params\"],\n",
    "        list_disc_params=cfg[\"list_check_model_params\"],\n",
    "        device=device,\n",
    "        path=cfg[\"disc_path\"],\n",
    "        train_mode=False,\n",
    "    )\n",
    "    if cfg[\"use_disc_check\"]\n",
    "    else None\n",
    ")\n",
    "estimator = AttackEstimator(disc_check_list, cfg[\"metric_effect\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.001\n",
    "eps = 0.03"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logging\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 50/50 [00:05<00:00,  9.70it/s]\n"
     ]
    }
   ],
   "source": [
    "attack_metrics = pd.DataFrame()\n",
    "attack_params = dict(cfg[\"attack\"][\"attack_params\"])\n",
    "attack_params[\"model\"] = attack_model\n",
    "attack_params[\"criterion\"] = criterion\n",
    "attack_params[\"estimator\"] = estimator\n",
    "attack_params[\"alpha\"] = alpha\n",
    "attack_params[\"eps\"] = eps\n",
    "\n",
    "if \"list_reg_model_params\" in cfg[\"attack\"]:\n",
    "    attack_params[\"disc_models\"] = get_disc_list(\n",
    "        model_name=cfg[\"disc_model_reg\"][\"name\"],\n",
    "        model_params=cfg[\"disc_model_reg\"][\"params\"],\n",
    "        list_disc_params=cfg[\"attack\"][\"list_reg_model_params\"],\n",
    "        device=device,\n",
    "        path=cfg[\"disc_path\"],\n",
    "        train_mode=cfg[\"disc_model_reg\"][\"attack_train_mode\"],\n",
    "    )\n",
    "\n",
    "attack = get_attack(cfg[\"attack\"][\"name\"], attack_params)\n",
    "X_adv = attack.apply_attack(test_loader).squeeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([400, 100])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66, 63, 77, 65, 52, 70, 80, 56, 49, 51, 63, 76, 96, 54, 63, 64, 70, 98,\n",
       "        72, 53, 70, 59, 79, 53, 61, 53, 63, 67, 80, 80, 60, 74, 51, 50, 91, 71,\n",
       "        59, 59, 70, 65, 51, 66, 56, 92, 91, 50, 74, 84, 86, 76, 62, 83, 60, 90,\n",
       "        70, 79, 83, 85, 68, 56, 72, 91, 83, 56, 60, 69, 98, 64, 57, 81, 97, 80,\n",
       "        83, 82, 68, 89, 68, 52, 53, 63, 80, 95, 75, 77, 98, 86, 70, 95, 68, 70,\n",
       "        54, 51, 52, 52, 70, 75, 53, 51, 91, 98, 89, 67, 59, 81, 59, 53, 68, 87,\n",
       "        68, 84, 77, 77, 99, 79, 64, 86, 75, 63, 86, 90, 77, 74, 87, 75, 57, 79,\n",
       "        97, 62, 62, 69, 95, 82, 84, 81, 66, 54, 70, 73, 65, 73, 64, 63, 78, 77,\n",
       "        92, 98, 93, 68, 86, 77, 80, 97, 61, 95, 58, 96, 55, 63, 72, 82, 50, 76,\n",
       "        70, 90, 55, 54, 63, 83, 68, 97, 52, 66, 91, 91, 58, 62, 66, 70, 84, 52,\n",
       "        56, 80, 82, 77, 80, 97, 63, 56, 52, 79, 67, 54, 84, 63, 63, 66, 86, 70,\n",
       "        61, 62, 62, 68, 85, 63, 83, 97, 87, 98, 90, 80, 69, 77, 94, 50, 76, 78,\n",
       "        63, 98, 96, 63, 52, 57, 75, 93, 83, 76, 85, 94, 91, 79, 98, 80, 68, 90,\n",
       "        83, 84, 74, 63, 94, 68, 72, 52, 80, 83, 97, 55, 76, 52, 63, 56, 97, 77,\n",
       "        74, 63, 84, 96, 88, 54, 55, 55, 97, 71, 55, 95, 91, 94, 55, 82, 96, 65,\n",
       "        56, 93, 56, 97, 56, 77, 50, 65, 81, 51, 90, 91, 95, 75, 73, 56, 56, 77,\n",
       "        93, 52, 76, 91, 98, 98, 91, 68, 96, 79, 78, 79, 86, 56, 91, 85, 87, 55,\n",
       "        51, 51, 69, 73, 97, 93, 83, 78, 88, 87, 73, 89, 77, 59, 81, 99, 89, 77,\n",
       "        87, 70, 83, 95, 91, 74, 84, 52, 97, 77, 70, 65, 86, 83, 87, 56, 65, 56,\n",
       "        57, 82, 65, 75, 98, 71, 83, 95, 83, 68, 77, 70, 91, 53, 59, 77, 91, 54,\n",
       "        58, 86, 76, 83, 97, 83, 62, 78, 97, 68, 86, 93, 70, 98, 91, 53, 77, 55,\n",
       "        72, 65, 77, 78, 56, 91, 61, 76, 66, 81, 88, 56, 93, 90, 75, 77, 86, 96,\n",
       "        64, 96, 84, 89])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = X_test.shape[1] - torch.sum(X_test == 0, axis=1)\n",
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "disc_preds = estimator.calculate_hid_one_model(\n",
    "    X_adv.unsqueeze(-1).to(device), \n",
    "    estimator.disc_models[0]\n",
    ") \\\n",
    ".detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([66, 63, 77, 65, 52, 70, 80, 56, 49, 51, 63, 76, 96, 54, 63, 64, 70, 98,\n",
       "        72, 53, 70, 59, 79, 53, 61, 53, 63, 67, 80, 80, 60, 74, 51, 50, 91, 71,\n",
       "        59, 59, 70, 65, 51, 66, 56, 92, 91, 50, 74, 84, 86, 76, 62, 83, 60, 90,\n",
       "        70, 79, 83, 85, 68, 56, 72, 91, 83, 56, 60, 69, 98, 64, 57, 81, 97, 80,\n",
       "        83, 82, 68, 89, 68, 52, 53, 63, 80, 95, 75, 77, 98, 86, 70, 95, 68, 70,\n",
       "        54, 51, 52, 52, 70, 75, 53, 51, 91, 98, 89, 67, 59, 81, 59, 53, 68, 87,\n",
       "        68, 84, 77, 77, 99, 79, 64, 86, 75, 63, 86, 90, 77, 74, 87, 75, 57, 79,\n",
       "        97, 62, 62, 69, 95, 82, 84, 81, 66, 54, 70, 73, 65, 73, 64, 63, 78, 77,\n",
       "        92, 98, 93, 68, 86, 77, 80, 97, 61, 95, 58, 96, 55, 63, 72, 82, 50, 76,\n",
       "        70, 90, 55, 54, 63, 83, 68, 97, 52, 66, 91, 91, 58, 62, 66, 70, 84, 52,\n",
       "        56, 80, 82, 77, 80, 97, 63, 56, 52, 79, 67, 54, 84, 63, 63, 66, 86, 70,\n",
       "        61, 62, 62, 68, 85, 63, 83, 97, 87, 98, 90, 80, 69, 77, 94, 50, 76, 78,\n",
       "        63, 98, 96, 63, 52, 57, 75, 93, 83, 76, 85, 94, 91, 79, 98, 80, 68, 90,\n",
       "        83, 84, 74, 63, 94, 68, 72, 52, 80, 83, 97, 55, 76, 52, 63, 56, 97, 77,\n",
       "        74, 63, 84, 96, 88, 54, 55, 55, 97, 71, 55, 95, 91, 94, 55, 82, 96, 65,\n",
       "        56, 93, 56, 97, 56, 77, 50, 65, 81, 51, 90, 91, 95, 75, 73, 56, 56, 77,\n",
       "        93, 52, 76, 91, 98, 98, 91, 68, 96, 79, 78, 79, 86, 56, 91, 85, 87, 55,\n",
       "        51, 51, 69, 73, 97, 93, 83, 78, 88, 87, 73, 89, 77, 59, 81, 99, 89, 77,\n",
       "        87, 70, 83, 95, 91, 74, 84, 52, 97, 77, 70, 65, 86, 83, 87, 56, 65, 56,\n",
       "        57, 82, 65, 75, 98, 71, 83, 95, 83, 68, 77, 70, 91, 53, 59, 77, 91, 54,\n",
       "        58, 86, 76, 83, 97, 83, 62, 78, 97, 68, 86, 93, 70, 98, 91, 53, 77, 55,\n",
       "        72, 65, 77, 78, 56, 91, 61, 76, 66, 81, 88, 56, 93, 90, 75, 77, 86, 96,\n",
       "        64, 96, 84, 89])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>disc_preds_prob</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>mean_seq_len</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>quantiles</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>54.259259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.644444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>75.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.917647</td>\n",
       "      <td>0.917647</td>\n",
       "      <td>84.423529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756757</td>\n",
       "      <td>0.756757</td>\n",
       "      <td>94.837838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           disc_preds_prob  Accuracy  mean_seq_len\n",
       "quantiles                                         \n",
       "0                 1.000000  1.000000     54.259259\n",
       "1                 1.000000  1.000000     65.644444\n",
       "2                 1.000000  1.000000     75.800000\n",
       "3                 0.917647  0.917647     84.423529\n",
       "4                 0.756757  0.756757     94.837838"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "array_lens_preds = np.concatenate([disc_preds.numpy(), lens.unsqueeze(1)], axis=1)\n",
    "df_lens_preds = pd.DataFrame(array_lens_preds, columns=['disc_preds_prob', 'lens'])\n",
    "df_lens_preds['disc_preds'] = np.round(df_lens_preds['disc_preds_prob'])\n",
    "df_lens_preds['quantiles'] = pd.qcut(df_lens_preds['lens'], 5, labels=False)\n",
    "\n",
    "agg_statistic = df_lens_preds.groupby('quantiles').agg({'disc_preds_prob': 'mean', 'disc_preds': 'mean', 'lens': 'mean'})\n",
    "agg_statistic = agg_statistic.rename(columns={\n",
    "    'disc_preds': 'Accuracy', \n",
    "    'mean_disc_pred': 'disc_preds_prob',\n",
    "    'lens': 'mean_seq_len',\n",
    "    })\n",
    "agg_statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
